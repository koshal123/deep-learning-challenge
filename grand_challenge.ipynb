{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grand_challenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koshal123/deep-learning-challenge/blob/master/grand_challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PgAiNEr3l3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T9_f_w1F6BJ",
        "colab_type": "text"
      },
      "source": [
        "#Importing Test/Train Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC8XP76RZwj8",
        "colab_type": "code",
        "outputId": "34974775-c459-43f7-c656-de990b99085f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        " !pip install -U -q PyDrive ## you will have install for every colab session\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)   "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 10.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 11.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 9.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 9.3MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 9.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 624kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 634kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 655kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 665kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 686kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 696kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 716kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 727kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 747kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 757kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 9.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 9.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 9.3MB/s \n",
            "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "USo6w3_63TB3",
        "colab": {}
      },
      "source": [
        "#Accessing the training data\n",
        "training_data = drive.CreateFile({'id':'1wfT8FqrxTpf-384jH1S9ec53uk1cktp9'})\n",
        "training_data.GetContentFile('training_set.zip')\n",
        "!unzip training_set.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkZ5LDfqMI6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accessing the test data\n",
        "test_data = drive.CreateFile({'id':'1S7QNdVXH9LHUvT29iVpSv9DQQGu4qefE'})\n",
        "test_data.GetContentFile('test_set.zip')\n",
        "!unzip test_set.zip "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TzKCYL3P2lV",
        "colab_type": "text"
      },
      "source": [
        "#Importing pixel size information of training set and test set from system"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjIGueZ0hkqD",
        "colab_type": "code",
        "outputId": "93d8d4c0-29df-4949-8246-dc2e690edf14",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#importing test set pixel size .csv file from system\n",
        "from google.colab import files\n",
        "uploaded = files.upload() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a761a161-c8c4-4052-bac9-f12de6b53be1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a761a161-c8c4-4052-bac9-f12de6b53be1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving test_set_pixel_size.csv to test_set_pixel_size.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Uaf0_YONzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "test_pixel= pd.read_csv('test_set_pixel_size.csv')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6ac43730-8fdf-45f4-b77d-2039b84b33ae",
        "id": "wAybFEnXO-Mt",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "#importing training set pixel size .csv file from system\n",
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ce1151c-1977-4cc7-a984-254d4d243e67\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8ce1151c-1977-4cc7-a984-254d4d243e67\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving training_set_pixel_size_and_hc.csv to training_set_pixel_size_and_hc.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWMIQN43O6mQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_pixel = pd.read_csv('training_set_pixel_size_and_hc.csv') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec7-Bhwkjp_B",
        "colab_type": "text"
      },
      "source": [
        "#Setting cuda as our device, Dynamically by using code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkPOFR9AyT-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWKuWaaujpDO",
        "colab_type": "code",
        "outputId": "320fd417-ab1c-457d-a0fc-18ef65aeccb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPblTUo8suvq",
        "colab_type": "text"
      },
      "source": [
        "#Creating mask generation for whole training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKimDmyk9bhq",
        "colab_type": "text"
      },
      "source": [
        "mask generation is only once,,  as otherwise images were unnecessary repeats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inhea7a67LF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "32a071a2-a17e-4e09-85db-889421552b99"
      },
      "source": [
        "#mask generation is only once\n",
        "#as otherwise images were unnecessary repeats\n",
        "\n",
        "''''import os \n",
        "import cv2\n",
        "\n",
        "def mask_generator(source_file_path, dest_file_path):\n",
        "    file_names = sorted([file for _,_,files in os.walk(source_file_path) for file in files])\n",
        "    for i, file_name in enumerate(file_names):\n",
        "        if i % 2 != 0:\n",
        "            im = cv2.imread(source_file_path+file_name)\n",
        "            imgray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
        "            ret,thresh = cv2.threshold(imgray,127,255,0)\n",
        "            im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "            ellipse = cv2.fitEllipse(contours[0])\n",
        "            im1 = cv2.ellipse(im,ellipse,(255,255,255),-1)\n",
        "            image_name = file_name.replace('Annotation', 'Mask')\n",
        "            cv2.imwrite(dest_file_path+image_name, im1)\n",
        "    \n",
        "    return 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-3cb14809771e>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    return 1\u001b[0m\n\u001b[0m            \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDv4ultNvox_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mask_generator('/content/training_set/','/content/drive/My Drive/Mask_HC18/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRMjJNZiybxs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install mlflow\n",
        "#import mlflow\n",
        "#import mlflow.pytorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY7mYaAMcM_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook \n",
        "import copy\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOSn_oc9XHjh",
        "colab_type": "text"
      },
      "source": [
        "#changing dataset to Torch form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGQ12_JWXFtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "class CHALLENGE18(torch.utils.data.Dataset):\n",
        "  def __init__(self, png_images, tranform=None,train=True):\n",
        "    self.X_train = glob.glob('/content/training_set/*HC.png')\n",
        "    \n",
        "    self.Y_train = glob.glob('/content/drive/My Drive/Mask_HC18/*')\n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "    self.png_images = png_images\n",
        "    \n",
        "  def __len__(self):\n",
        "    if self.png_images == \"train\":\n",
        "      return len(self.X_train)\n",
        "    else:\n",
        "      print(\"code is wrong\")\n",
        "      \n",
        "  def __getitem__(self,idx):\n",
        "    if self.png_images == \"train\":\n",
        "      \n",
        "      X=np.array(Image.open(self.X_train[idx]).resize((572,572))).reshape(1,572,572) #as per U-net paper\n",
        "      \n",
        "      Y=np.array(Image.open(self.Y_train[idx]).convert('L').resize((572,572))).reshape(1,572,572)\n",
        "      \n",
        "      \n",
        "      print(X.shape, Y.shape)\n",
        "      \n",
        "      return torch.from_numpy(X).float(), torch.from_numpy(Y).float()\n",
        "    \n",
        "    else:\n",
        "      print(\"code is wrong\")\n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvYs4E5SloLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_images = CHALLENGE18(\"train\", train=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDkYByL0HL8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#total_images[5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsFHHVWnpFiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = int(0.7 * len(total_images))\n",
        "\n",
        "test_images = len(total_images)- train_images\n",
        "\n",
        "train_data, validation_data = random_split(total_images,[train_images, test_images])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuJBu9wS53m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_data[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SR_Y065p4HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 2\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_data = CHALLENGE18(\"test\",train=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2lUJYk1qkRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img, title):\n",
        "    img = img.clone().detach().numpy()\n",
        "    #npimg = img * ((0.5,0.5,0.5)) + 0.5   # un-normalizing the image\n",
        "    #plt.figure(figsize=(batch_size*5, 5))\n",
        "    #plt.axis('off')\n",
        "    #img = np.transpose(img, (1, 2, 0))\n",
        "    print('npimage shape',img.shape)\n",
        "    #plt.imshow(npimg)\n",
        "    #plt.title(title)\n",
        "    plt.show()\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CcQ1lPNq07T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_train_batch_images(dataloader):\n",
        "    x, y = next(iter(dataloader))\n",
        "    print(x.shape)\n",
        "    return imshow(x[0],'d')\n",
        "    \n",
        "    #x = torchvision.utils.make_grid(x)\n",
        "    #y = torchvision.utils.make_grid(y)\n",
        "    #imshow(x, title=[n for n in xf])\n",
        "    #imshow(y, title=[n for n in yf])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORJ_qJf1q8rV",
        "colab_type": "code",
        "outputId": "d9bcd2bc-27d2-4a53-e620-92737ac79b3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "p =show_train_batch_images(validation_loader)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 572, 572) (1, 572, 572)\n",
            "(1, 572, 572) (1, 572, 572)\n",
            "torch.Size([2, 1, 572, 572])\n",
            "npimage shape (1, 572, 572)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnkIavrcqyBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#q= show_train_batch_images(train_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9dsNlGqL2Mn",
        "colab_type": "code",
        "outputId": "3f6e2c8d-d436-4cde-9776-18b9a3792e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "p.shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 572, 572)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxRJDArFMDM6",
        "colab_type": "code",
        "outputId": "ac543cce-8f17-4367-fad2-607c4860a32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(p.reshape(572,572))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07OFr-ZWMF3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.imshow(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1rz4QcJ0PIb",
        "colab_type": "text"
      },
      "source": [
        "#prepare for U-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0IbryRfk4Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#as in the dataset, rarely any image has features in the boundary, so I am not considering the padding\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UNet, self).__init__()\n",
        "    self.direct_1 = self.direct(1)\n",
        "    self.down_1 = self.down(64)   #as per UNet paper, no of channels doubles per pooling in downside\n",
        "    self.down_2 = self.down(128)\n",
        "    self.down_3 = self.down(256)\n",
        "    self.lowest_4 = self.lowest(512)\n",
        "\n",
        "\n",
        "    self.up_layer_4 = self.up_conv(1024)\n",
        "    self.up_4 = self.up(1024)\n",
        "    \n",
        "    self.up_layer_3 = self.up_conv(512)\n",
        "    self.up_3 = self.up(512)\n",
        "    \n",
        "    self.up_layer_2 = self.up_conv(256)\n",
        "    self.up_2 = self.up(256)\n",
        "    \n",
        "    self.up_layer_1 = self.up_conv(128)\n",
        "    self.up_1 = self.up(128)\n",
        "    \n",
        "    self.final_output = nn.Conv2d(64,2, 1, 1)   #kernel size = 1 and stride = 1\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#function for first convolutional layer   \n",
        "\n",
        "  def direct(self,input_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(1,64, 3, 1,0),    #(input_channel= 1, output_channel = 64, kernel_size = 3, stride = 1)\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(64,64, 3, 1,0),\n",
        "        nn.ReLU(inplace = True)\n",
        "    )   \n",
        "\n",
        "# function for pooling \n",
        "\n",
        "  def pooling(self):\n",
        "    return nn.MaxPool2d(2,2)   #max-pool-kernel(2*2)\n",
        "\n",
        "#function for the contracting downside layers\n",
        "\n",
        "  def down(self, input_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(input_channels, int(2* input_channels), 3, 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(int(2*input_channels), int(2* input_channels), 3, 1),\n",
        "        nn.ReLU(inplace = True)\n",
        "    )\n",
        "\n",
        "#function for lowest layer\n",
        "\n",
        "  def lowest(self, input_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(input_channels, 2* input_channels, 3, 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(2* input_channels, 2* input_channels, 3, 1),\n",
        "        nn.ReLU(inplace = True)\n",
        "    )\n",
        "\n",
        "    \n",
        "#function for upward layer\n",
        "\n",
        "  def up(self, input_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(int(input_channels), int(0.5* input_channels), 3, 1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.Conv2d(int(0.5* input_channels), int(0.5* input_channels), 3, 1), #no change in channels\n",
        "        nn.ReLU(inplace = True)\n",
        "    )\n",
        "\n",
        "  #def up_conv(self, input_channels):\n",
        "    #return nn.ConvTranspose2d(input_channels, int(0.5 * input_channels), 2,  2)  #feture detector has size= (2,2)\n",
        "      \n",
        "    \n",
        "  def up_conv(self, input_channels):   #kernel size=2, stride =1\n",
        "    return nn.ConvTranspose2d(input_channels, input_channels, 2,  2)  #feture detector has size=2, and stride= 1\n",
        "                      \n",
        "#function for copy and crop\n",
        "  def crop_concat(self, x1, x2):\n",
        "    \n",
        "    in_width = x1.shape[-1]\n",
        "    out_width = x2.shape[-1]\n",
        "    crop_width = (in_width - out_width) // 2\n",
        "    in_height = x1.shape[-2]\n",
        "    out_height = x2.shape[-2]\n",
        "    crop_height = (in_height - out_height) // 2\n",
        "  \n",
        "    x1 = x1[:, :, crop_height:(in_height-crop_height), crop_width:(in_width-crop_width)]\n",
        "    \n",
        "    return torch.cat([x1, x2],1)\n",
        "    \n",
        "     \n",
        "  def forward(self, x):\n",
        "    \n",
        "#downside movement of layers\n",
        "    x1 = self.direct_1(x)\n",
        "    print(x1.shape)\n",
        "    x2 = self.down_1(self.pooling()(x1))\n",
        "    x3 = self.down_2(self.pooling()(x2))\n",
        "    x4 = self.down_3(self.pooling()(x3))\n",
        "    x5 = self.lowest_4(self.pooling()(x4))\n",
        "    print(x5.shape) \n",
        "#upside movement\n",
        "    x4_u = self.up_layer_4(x5)\n",
        "    \n",
        "    x4_u = self.up_4(self.crop_concat(x4, x4_u))\n",
        "    print(x4_u.shape)\n",
        "    x3_u = self.up_layer_3(x4_u)\n",
        "    x3_u = self.up_3(self.crop_concat(x3, x3_u))\n",
        "    \n",
        "    x2_u = self.up_layer_2(x3_u)\n",
        "    x2_u = self.up_2(self.crop_concat(x2, x2_u))\n",
        "    \n",
        "    #print(x2_u.shape)\n",
        "    \n",
        "    x1_u = self.up_layer_1(x2_u)\n",
        "    x1_u = self.up_1(self.crop_concat(x1, x1_u))\n",
        "    \n",
        "    y= self.final_output(x1_u)\n",
        "    return y\n",
        "    \n",
        "  \n",
        "unet = UNet()\n",
        "unet= unet.to(device)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPSoNFx6bdH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(unet.parameters(), lr=0.01, momentum= 0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klz34VhE5NO6",
        "colab_type": "text"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl2WMWaCk417",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for epoch in range(5):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    \n",
        "    inputs = inputs.to(device)\n",
        "    \n",
        "    \n",
        "    inputs, labels = data\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    outputs = unet(inputs)\n",
        "    \n",
        "    outputs = outputs.to(device)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    \n",
        "    running_loss += loss.item()\n",
        "    if i % 2000 == 1999:\n",
        "      print('[%d, %5d] loss:%.3f' % (epoch + 1, i +1, running_loss / 2000))\n",
        "      \n",
        "      running_loss = 0.0\n",
        "      \n",
        "print(\"training is finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P0fk0zHlKud",
        "colab_type": "text"
      },
      "source": [
        "#Dice coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtD-eJtxZmM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coeff(pred, target):\n",
        "    smooth = 1.\n",
        "    num = pred.size(0)\n",
        "    m1 = pred.view(num, -1)  # Flatten\n",
        "    m2 = target.view(num, -1)  # Flatten\n",
        "    intersection = (m1 * m2).sum()\n",
        "\n",
        "    return (2. * intersection + smooth) / (m1.sum() + m2.sum() + smooth)\n",
        "       \n",
        "\n",
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, inputs, targets):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        targets=targets.to(device)\n",
        "        \n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        outputs = outputs.argmax(1).float()\n",
        "        \n",
        "        height, width = outputs.shape[1:]\n",
        "        \n",
        "        for output, target in zip(outputs, targets):\n",
        "          diceCoeff += dice_coeff(output.view(1, 1, height, width), target.view(1, 1, height, width))\n",
        "          \n",
        "          \n",
        "          diceCoeff /= len(dataloader.dataset)\n",
        "          \n",
        "          return diceCoeff\n",
        "\n",
        "    #def forward(self, logits, targets):\n",
        "    #    probs = F.sigmoid(logits)\n",
        "     #   num = targets.size(0)  # Number of batches\n",
        "\n",
        "#        score = dice_coeff(probs, targets)\n",
        " #       score = 1 - score.sum() / num\n",
        "  #      return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmwrEgg8s3uT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}